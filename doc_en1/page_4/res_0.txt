{"type": "text", "bbox": [887, 1123, 1556, 1580], "res": [{"text": "the experiments show that this strategy also is effective.", "confidence": 0.9877183437347412, "text_region": [[882.0, 1095.0], [1504.0, 1095.0], [1504.0, 1125.0], [882.0, 1125.0]]}, {"text": "FPGM Pruner Pruning is another method to improve", "confidence": 0.9895215630531311, "text_region": [[912.0, 1125.0], [1554.0, 1125.0], [1554.0, 1155.0], [912.0, 1155.0]]}, {"text": "the inference efficiency of neural network model. In order", "confidence": 0.990606427192688, "text_region": [[885.0, 1155.0], [1552.0, 1155.0], [1552.0, 1185.0], [885.0, 1185.0]]}, {"text": "to avoid the model performance degradation caused by the", "confidence": 0.9964552521705627, "text_region": [[885.0, 1187.0], [1552.0, 1187.0], [1552.0, 1217.0], [885.0, 1217.0]]}, {"text": "model pruning, we use FPGM (He et al. 2019b) to find the", "confidence": 0.9934538006782532, "text_region": [[885.0, 1217.0], [1552.0, 1217.0], [1552.0, 1247.0], [885.0, 1247.0]]}, {"text": "unimportant sub-network in original models. FPGM uses", "confidence": 0.9858760237693787, "text_region": [[887.0, 1247.0], [1552.0, 1247.0], [1552.0, 1276.0], [887.0, 1276.0]]}, {"text": "geometric median as the criterion and the each filter in a con-", "confidence": 0.9722103476524353, "text_region": [[885.0, 1279.0], [1552.0, 1276.0], [1552.0, 1306.0], [885.0, 1309.0]]}, {"text": "volution layer is considered as a point in Euclidean space.", "confidence": 0.9944251775741577, "text_region": [[885.0, 1306.0], [1550.0, 1309.0], [1550.0, 1338.0], [885.0, 1336.0]]}, {"text": "Then calculate the geometric median of these points and re.", "confidence": 0.9925271272659302, "text_region": [[885.0, 1338.0], [1545.0, 1338.0], [1545.0, 1368.0], [885.0, 1368.0]]}, {"text": "move the filters with the similar values, as shown in Figure", "confidence": 0.9914495348930359, "text_region": [[885.0, 1366.0], [1548.0, 1368.0], [1547.0, 1400.0], [885.0, 1398.0]]}, {"text": "The compress ratio of each layer is also important for prun-", "confidence": 0.9883379340171814, "text_region": [[887.0, 1400.0], [1548.0, 1400.0], [1548.0, 1430.0], [887.0, 1430.0]]}, {"text": "ing a model. Pruning every layer uniformly usually leads to", "confidence": 0.9932883977890015, "text_region": [[885.0, 1430.0], [1552.0, 1430.0], [1552.0, 1460.0], [885.0, 1460.0]]}, {"text": "significant performance degradation. In PP-OCR, the prun-", "confidence": 0.989639401435852, "text_region": [[885.0, 1460.0], [1552.0, 1460.0], [1552.0, 1490.0], [885.0, 1490.0]]}, {"text": "ing sensitivity of each layer is calculated according to the", "confidence": 0.9988439679145813, "text_region": [[882.0, 1492.0], [1552.0, 1490.0], [1552.0, 1519.0], [882.0, 1522.0]]}, {"text": "method in (Li et al. 2016) and then used to evaluate the re-", "confidence": 0.9862641096115112, "text_region": [[882.0, 1519.0], [1550.0, 1519.0], [1550.0, 1549.0], [882.0, 1549.0]]}, {"text": " dundancy of each layer.", "confidence": 0.98343425989151, "text_region": [[883.0, 1549.0], [1153.0, 1552.0], [1152.0, 1584.0], [882.0, 1581.0]]}], "img_idx": 0, "score": 0.9884930849075317}
{"type": "text", "bbox": [150, 1618, 818, 1956], "res": [{"text": "from 4.1M to 2.5M, but the accuracy has no effect.", "confidence": 0.9820930361747742, "text_region": [[146.0, 1590.0], [721.0, 1590.0], [721.0, 1620.0], [146.0, 1620.0]]}, {"text": "Cosine Learning Rate Decay The learning rate is the", "confidence": 0.997575581073761, "text_region": [[176.0, 1622.0], [815.0, 1622.0], [815.0, 1652.0], [176.0, 1652.0]]}, {"text": "hyperparameter to control the learning speed. The lower", "confidence": 0.9850775003433228, "text_region": [[148.0, 1655.0], [815.0, 1655.0], [815.0, 1684.0], [148.0, 1684.0]]}, {"text": "the learning rate, the slower the change of the loss value", "confidence": 0.9883878827095032, "text_region": [[148.0, 1684.0], [808.0, 1684.0], [808.0, 1714.0], [148.0, 1714.0]]}, {"text": "Though using a low learning rate can ensure that you will", "confidence": 0.9998974204063416, "text_region": [[150.0, 1714.0], [813.0, 1714.0], [813.0, 1744.0], [150.0, 1744.0]]}, {"text": "not miss any local minimum, but it also means that the con-", "confidence": 0.9945268034934998, "text_region": [[148.0, 1744.0], [808.0, 1744.0], [808.0, 1774.0], [148.0, 1774.0]]}, {"text": "vergence speed is slow. In the early stage of training, the", "confidence": 0.9909101724624634, "text_region": [[150.0, 1778.0], [813.0, 1778.0], [813.0, 1801.0], [150.0, 1801.0]]}, {"text": "weights are in random initialization state, so we can set a", "confidence": 0.9859370589256287, "text_region": [[150.0, 1806.0], [815.0, 1806.0], [815.0, 1836.0], [150.0, 1836.0]]}, {"text": "relatively large learning rate for faster convergence. In the", "confidence": 0.9934393167495728, "text_region": [[146.0, 1833.0], [813.0, 1836.0], [813.0, 1865.0], [145.0, 1863.0]]}, {"text": "late stage of training, the weights are close to the optimal", "confidence": 0.9952784180641174, "text_region": [[146.0, 1868.0], [815.0, 1868.0], [815.0, 1898.0], [146.0, 1898.0]]}, {"text": "values, so a relatively smaller learning rate should be used.", "confidence": 0.9969328045845032, "text_region": [[148.0, 1898.0], [813.0, 1898.0], [813.0, 1927.0], [148.0, 1927.0]]}, {"text": "Cosine learning rate decay has become the preferred learn-", "confidence": 0.9881185293197632, "text_region": [[150.0, 1932.0], [811.0, 1932.0], [811.0, 1955.0], [150.0, 1955.0]]}], "img_idx": 0, "score": 0.9884369969367981}
{"type": "text", "bbox": [149, 1220, 819, 1618], "res": [{"text": " reduced from 7M to 4.1M, but the accuracy declines slightly", "confidence": 0.9937680959701538, "text_region": [[143.0, 1187.0], [808.0, 1189.0], [808.0, 1221.0], [143.0, 1219.0]]}, {"text": "Remove SE SE is the short for squeeze-and-excitation", "confidence": 0.9997795820236206, "text_region": [[176.0, 1224.0], [815.0, 1224.0], [815.0, 1254.0], [176.0, 1254.0]]}, {"text": "(Hu, Shen, and Sun 2018). As shown in Figure7 SE blocks", "confidence": 0.9849972128868103, "text_region": [[148.0, 1254.0], [815.0, 1254.0], [815.0, 1283.0], [148.0, 1283.0]]}, {"text": "model inter-dependencies between channels explicitly and", "confidence": 0.9893211722373962, "text_region": [[150.0, 1286.0], [815.0, 1286.0], [815.0, 1315.0], [150.0, 1315.0]]}, {"text": "re-calibrate channel-wise feature responses adaptively. Be-", "confidence": 0.9964479804039001, "text_region": [[146.0, 1313.0], [811.0, 1313.0], [811.0, 1343.0], [146.0, 1343.0]]}, {"text": "cause SE blocks can improve the accuracy of the vision tasks", "confidence": 0.9937222599983215, "text_region": [[148.0, 1345.0], [813.0, 1345.0], [813.0, 1375.0], [148.0, 1375.0]]}, {"text": "obviously, the search space of MobileNetV3 contains them", "confidence": 0.9975403547286987, "text_region": [[150.0, 1380.0], [813.0, 1380.0], [813.0, 1402.0], [150.0, 1402.0]]}, {"text": "and numerous of SE blocks are in MobileNetV3 architec-", "confidence": 0.999473512172699, "text_region": [[148.0, 1407.0], [813.0, 1407.0], [813.0, 1437.0], [148.0, 1437.0]]}, {"text": "ture. However, when the input resolution is large, such as", "confidence": 0.9898681044578552, "text_region": [[146.0, 1437.0], [815.0, 1437.0], [815.0, 1467.0], [146.0, 1467.0]]}, {"text": "640  640, it is hard to estimate the channel-wise feature", "confidence": 0.9965636134147644, "text_region": [[150.0, 1471.0], [813.0, 1471.0], [813.0, 1494.0], [150.0, 1494.0]]}, {"text": "responses with the SE block. The accuracy improvement is", "confidence": 0.9954343438148499, "text_region": [[148.0, 1496.0], [815.0, 1496.0], [815.0, 1526.0], [148.0, 1526.0]]}, {"text": "limited, but the time cost is very high. When the SE blocks", "confidence": 0.9848974943161011, "text_region": [[146.0, 1529.0], [815.0, 1529.0], [815.0, 1558.0], [146.0, 1558.0]]}, {"text": "are removed from the backbone, the model size is reduced", "confidence": 0.9880048036575317, "text_region": [[148.0, 1558.0], [815.0, 1558.0], [815.0, 1588.0], [148.0, 1588.0]]}, {"text": "from 4.1M to 2.5M, but the accuracy has no effect.", "confidence": 0.9820930361747742, "text_region": [[146.0, 1590.0], [721.0, 1590.0], [721.0, 1620.0], [146.0, 1620.0]]}], "img_idx": 0, "score": 0.982033908367157}
{"type": "text", "bbox": [887, 877, 1556, 1124], "res": [{"text": "8compares the different ways of learning rate decay.", "confidence": 0.9904895424842834, "text_region": [[882.0, 850.0], [1481.0, 850.0], [1481.0, 880.0], [882.0, 880.0]]}, {"text": "Learning Rate Warm-up The paper (He et al.2019a)", "confidence": 0.9787194132804871, "text_region": [[910.0, 880.0], [1547.0, 878.0], [1548.0, 910.0], [910.0, 912.0]]}, {"text": "shows that using learning rate warm-up operation can help", "confidence": 0.9998177886009216, "text_region": [[887.0, 912.0], [1552.0, 912.0], [1552.0, 942.0], [887.0, 942.0]]}, {"text": "to improve the accuracy in the image classification. At the", "confidence": 0.9923535585403442, "text_region": [[889.0, 946.0], [1550.0, 946.0], [1550.0, 969.0], [889.0, 969.0]]}, {"text": "beginning of the training process, using a too large learning", "confidence": 0.9962137341499329, "text_region": [[882.0, 969.0], [1552.0, 972.0], [1552.0, 1004.0], [882.0, 1001.0]]}, {"text": "rate may result in numerical instability, a small learning rate", "confidence": 0.9913748502731323, "text_region": [[885.0, 1001.0], [1554.0, 1001.0], [1554.0, 1034.0], [885.0, 1034.0]]}, {"text": "is recommended to be used. When the training process is sta-", "confidence": 0.998359739780426, "text_region": [[885.0, 1034.0], [1548.0, 1034.0], [1548.0, 1063.0], [885.0, 1063.0]]}, {"text": "ble, the initial learning rate is to be used. For text detection,", "confidence": 0.987600564956665, "text_region": [[882.0, 1063.0], [1552.0, 1063.0], [1552.0, 1093.0], [882.0, 1093.0]]}, {"text": "the experiments show that this strategy also is effective.", "confidence": 0.9877183437347412, "text_region": [[882.0, 1095.0], [1504.0, 1095.0], [1504.0, 1125.0], [882.0, 1125.0]]}], "img_idx": 0, "score": 0.9675897359848022}
{"type": "text", "bbox": [888, 1740, 1557, 1924], "res": [{"text": "Light Backbone We also adopt MobileNetV3 as the", "confidence": 0.9920104742050171, "text_region": [[915.0, 1746.0], [1550.0, 1746.0], [1550.0, 1769.0], [915.0, 1769.0]]}, {"text": "backbone of the direction classifier which is the same as", "confidence": 0.9871967434883118, "text_region": [[885.0, 1774.0], [1552.0, 1774.0], [1552.0, 1804.0], [885.0, 1804.0]]}, {"text": "the text detector. Because this task is relatively simple, we", "confidence": 0.9970255494117737, "text_region": [[887.0, 1808.0], [1550.0, 1808.0], [1550.0, 1831.0], [887.0, 1831.0]]}, {"text": "use MobileNetV3_small_x0.35 to balance accuracy and effi-", "confidence": 0.9906162023544312, "text_region": [[885.0, 1836.0], [1548.0, 1836.0], [1548.0, 1865.0], [885.0, 1865.0]]}, {"text": "ciency empirically. When using larger backbones, the accu-", "confidence": 0.9934396147727966, "text_region": [[889.0, 1870.0], [1548.0, 1870.0], [1548.0, 1893.0], [889.0, 1893.0]]}, {"text": "racy doesn't improve more.", "confidence": 0.9990618824958801, "text_region": [[887.0, 1900.0], [1192.0, 1900.0], [1192.0, 1923.0], [887.0, 1923.0]]}], "img_idx": 0, "score": 0.9630521535873413}
{"type": "text", "bbox": [150, 1034, 819, 1220], "res": [{"text": "short). The probability map and the threshold map are gen-", "confidence": 0.9898182153701782, "text_region": [[148.0, 1038.0], [808.0, 1038.0], [808.0, 1068.0], [148.0, 1068.0]]}, {"text": "erated from the fused feature map with convolutions which", "confidence": 0.9948675036430359, "text_region": [[148.0, 1068.0], [815.0, 1068.0], [815.0, 1098.0], [148.0, 1098.0]]}, {"text": "are also associated with the above inner channels. Thus in-", "confidence": 0.9851431846618652, "text_region": [[146.0, 1098.0], [811.0, 1100.0], [811.0, 1130.0], [145.0, 1127.0]]}, {"text": "ner channels has a great influence on the model size. When", "confidence": 0.9873606562614441, "text_region": [[148.0, 1130.0], [815.0, 1130.0], [815.0, 1160.0], [148.0, 1160.0]]}, {"text": "inner channels is reduced from 256 to 96, the model size is", "confidence": 0.9810064435005188, "text_region": [[146.0, 1160.0], [813.0, 1160.0], [813.0, 1189.0], [146.0, 1189.0]]}, {"text": " reduced from 7M to 4.1M, but the accuracy declines slightly", "confidence": 0.9937680959701538, "text_region": [[143.0, 1187.0], [808.0, 1189.0], [808.0, 1221.0], [143.0, 1219.0]]}], "img_idx": 0, "score": 0.9611470699310303}
{"type": "text", "bbox": [886, 725, 1557, 879], "res": [{"text": "ing rate reduction strategy for improving model accuracy", "confidence": 0.992003858089447, "text_region": [[885.0, 729.0], [1548.0, 729.0], [1548.0, 759.0], [885.0, 759.0]]}, {"text": "During the entire training process, cosine learning rate de", "confidence": 0.9952369332313538, "text_region": [[887.0, 761.0], [1543.0, 761.0], [1543.0, 784.0], [887.0, 784.0]]}, {"text": "cay keeps a relatively large learning rate, so its convergence", "confidence": 0.9957629442214966, "text_region": [[887.0, 791.0], [1552.0, 791.0], [1552.0, 820.0], [887.0, 820.0]]}, {"text": "is slower, but the final convergence accuracy is better. Figure", "confidence": 0.9983152151107788, "text_region": [[885.0, 818.0], [1554.0, 818.0], [1554.0, 848.0], [885.0, 848.0]]}, {"text": "8compares the different ways of learning rate decay.", "confidence": 0.9904895424842834, "text_region": [[882.0, 850.0], [1481.0, 850.0], [1481.0, 880.0], [882.0, 880.0]]}], "img_idx": 0, "score": 0.9561124444007874}
{"type": "text", "bbox": [887, 1648, 1556, 1742], "res": [{"text": "In this section, the details of four strategies for enhancing", "confidence": 0.9964665770530701, "text_region": [[882.0, 1650.0], [1552.0, 1652.0], [1552.0, 1682.0], [882.0, 1680.0]]}, {"text": "the model ability or reducing the model size of a direction", "confidence": 0.9996914863586426, "text_region": [[887.0, 1687.0], [1552.0, 1687.0], [1552.0, 1710.0], [887.0, 1710.0]]}, {"text": "classifier will be introduced.", "confidence": 0.9975427985191345, "text_region": [[887.0, 1716.0], [1199.0, 1716.0], [1199.0, 1739.0], [887.0, 1739.0]]}], "img_idx": 0, "score": 0.9327976107597351}
{"type": "text", "bbox": [885, 601, 1554, 667], "res": [{"text": "Figure 9: Illustration of FPGM Pruner. This figure comes", "confidence": 0.9780021905899048, "text_region": [[885.0, 600.0], [1552.0, 603.0], [1552.0, 635.0], [885.0, 632.0]]}, {"text": "from the paper (He et al. 2019b)", "confidence": 0.9995960593223572, "text_region": [[885.0, 635.0], [1247.0, 635.0], [1247.0, 667.0], [885.0, 667.0]]}], "img_idx": 0, "score": 0.9251192808151245}
{"type": "text", "bbox": [149, 907, 814, 970], "res": [{"text": "Figure 8: Comparison of different ways of learning rate de-", "confidence": 0.9865990877151489, "text_region": [[148.0, 910.0], [813.0, 910.0], [813.0, 940.0], [148.0, 940.0]]}, {"text": "cay.", "confidence": 0.9998921751976013, "text_region": [[148.0, 944.0], [196.0, 944.0], [196.0, 972.0], [148.0, 972.0]]}], "img_idx": 0, "score": 0.924444317817688}
{"type": "text", "bbox": [158, 313, 781, 379], "res": [{"text": "Figure 7: Architecture of the SE block. This figure comes", "confidence": 0.9888006448745728, "text_region": [[148.0, 316.0], [815.0, 316.0], [815.0, 346.0], [148.0, 346.0]]}, {"text": "from the paper (Hu, Shen, and Sun|2018)", "confidence": 0.9857121109962463, "text_region": [[148.0, 348.0], [610.0, 348.0], [610.0, 378.0], [148.0, 378.0]]}], "img_idx": 0, "score": 0.8360406756401062}
{"type": "title", "bbox": [887, 1605, 1260, 1641], "res": [{"text": "2.2Direction Classification", "confidence": 0.9997990727424622, "text_region": [[885.0, 1611.0], [1259.0, 1611.0], [1259.0, 1641.0], [885.0, 1641.0]]}], "img_idx": 0, "score": 0.8416439890861511}
{"type": "figure", "bbox": [895, 157, 1545, 577], "res": [{"text": "Filter Space", "confidence": 0.9881739020347595, "text_region": [[991.0, 165.0], [1111.0, 165.0], [1111.0, 190.0], [991.0, 190.0]]}, {"text": "Large norm", "confidence": 0.9996848106384277, "text_region": [[991.0, 202.0], [1111.0, 202.0], [1111.0, 227.0], [991.0, 227.0]]}, {"text": "Previous", "confidence": 0.9997305870056152, "text_region": [[1223.0, 222.0], [1315.0, 227.0], [1313.0, 259.0], [1221.0, 254.0]]}, {"text": "Medium norm", "confidence": 0.9964555501937866, "text_region": [[979.0, 236.0], [1123.0, 236.0], [1123.0, 261.0], [979.0, 261.0]]}, {"text": " method", "confidence": 0.9311155676841736, "text_region": [[1229.0, 259.0], [1307.0, 259.0], [1307.0, 284.0], [1229.0, 284.0]]}, {"text": "Small norm", "confidence": 0.9999569058418274, "text_region": [[991.0, 270.0], [1111.0, 270.0], [1111.0, 296.0], [991.0, 296.0]]}, {"text": "Pruning", "confidence": 0.9998555779457092, "text_region": [[1123.0, 376.0], [1217.0, 376.0], [1217.0, 408.0], [1123.0, 408.0]]}, {"text": "Our", "confidence": 0.9992678761482239, "text_region": [[1257.0, 497.0], [1296.0, 497.0], [1296.0, 522.0], [1257.0, 522.0]]}, {"text": "Filters before pruning", "confidence": 0.9837977886199951, "text_region": [[892.0, 527.0], [1130.0, 532.0], [1129.0, 564.0], [891.0, 559.0]]}, {"text": "method", "confidence": 0.999849796295166, "text_region": [[1236.0, 527.0], [1312.0, 527.0], [1312.0, 552.0], [1236.0, 552.0]]}], "img_idx": 0, "score": 0.9725155830383301}
{"type": "figure", "bbox": [153, 416, 810, 882], "res": [{"text": "Comparison of different ways of learning rate decay", "confidence": 0.9944219589233398, "text_region": [[245.0, 417.0], [788.0, 419.0], [788.0, 449.0], [245.0, 447.0]]}, {"text": "0.10 -", "confidence": 0.9721734523773193, "text_region": [[176.0, 454.0], [226.0, 454.0], [226.0, 481.0], [176.0, 481.0]]}, {"text": "cosine_decay", "confidence": 0.9998354911804199, "text_region": [[644.0, 463.0], [762.0, 463.0], [762.0, 486.0], [644.0, 486.0]]}, {"text": "piecewise_decay", "confidence": 0.9996671080589294, "text_region": [[644.0, 488.0], [792.0, 488.0], [792.0, 513.0], [644.0, 513.0]]}, {"text": "0.08 -", "confidence": 0.996905505657196, "text_region": [[176.0, 522.0], [226.0, 522.0], [226.0, 550.0], [176.0, 550.0]]}, {"text": "0.06 -", "confidence": 0.9969010353088379, "text_region": [[176.0, 591.0], [226.0, 591.0], [226.0, 619.0], [176.0, 619.0]]}, {"text": "L", "confidence": 0.5813128352165222, "text_region": [[155.0, 632.0], [166.0, 632.0], [166.0, 646.0], [155.0, 646.0]]}, {"text": "0.04 -", "confidence": 0.9294597506523132, "text_region": [[174.0, 652.0], [230.0, 659.0], [226.0, 693.0], [170.0, 686.0]]}, {"text": "0.02 -", "confidence": 0.9939637780189514, "text_region": [[176.0, 726.0], [226.0, 726.0], [226.0, 754.0], [176.0, 754.0]]}, {"text": "0.00 -", "confidence": 0.9847739338874817, "text_region": [[173.0, 795.0], [226.0, 795.0], [226.0, 823.0], [173.0, 823.0]]}, {"text": "0", "confidence": 0.980073869228363, "text_region": [[240.0, 834.0], [261.0, 834.0], [261.0, 855.0], [240.0, 855.0]]}, {"text": "20", "confidence": 0.9992263317108154, "text_region": [[321.0, 832.0], [356.0, 832.0], [356.0, 859.0], [321.0, 859.0]]}, {"text": "40", "confidence": 0.9976412653923035, "text_region": [[411.0, 832.0], [446.0, 832.0], [446.0, 859.0], [411.0, 859.0]]}, {"text": " 60", "confidence": 0.906977653503418, "text_region": [[497.0, 832.0], [531.0, 832.0], [531.0, 859.0], [497.0, 859.0]]}, {"text": "80", "confidence": 0.9982882738113403, "text_region": [[584.0, 832.0], [621.0, 832.0], [621.0, 859.0], [584.0, 859.0]]}, {"text": "100", "confidence": 0.999473512172699, "text_region": [[670.0, 832.0], [714.0, 832.0], [714.0, 859.0], [670.0, 859.0]]}, {"text": "120", "confidence": 0.999675989151001, "text_region": [[760.0, 832.0], [799.0, 832.0], [799.0, 859.0], [760.0, 859.0]]}, {"text": "epoch", "confidence": 0.9987888336181641, "text_region": [[485.0, 859.0], [550.0, 859.0], [550.0, 882.0], [485.0, 882.0]]}], "img_idx": 0, "score": 0.9308295249938965}
{"type": "figure", "bbox": [168, 156, 812, 289], "res": [], "img_idx": 0, "score": 0.8924591541290283}
