{"type": "text", "bbox": [887, 1158, 1556, 1678], "res": [{"text": "To verify the advantages of each strategy, the setting of", "confidence": 0.996103048324585, "text_region": [[912.0, 1157.0], [1552.0, 1160.0], [1552.0, 1192.0], [912.0, 1189.0]]}, {"text": "the basic experimental is the strategy S1. When using BDA,", "confidence": 0.9944144487380981, "text_region": [[885.0, 1192.0], [1548.0, 1192.0], [1548.0, 1221.0], [885.0, 1221.0]]}, {"text": "the accuracy will be improved 3.12%. Data augmentation", "confidence": 0.9765419960021973, "text_region": [[885.0, 1221.0], [1554.0, 1221.0], [1554.0, 1251.0], [885.0, 1251.0]]}, {"text": "is very necessary for text recognition. When we adopt the", "confidence": 0.9909440279006958, "text_region": [[882.0, 1251.0], [1552.0, 1251.0], [1552.0, 1281.0], [882.0, 1281.0]]}, {"text": "cosine learning rate decay further, the accuracy will be im-", "confidence": 0.9977477788925171, "text_region": [[885.0, 1283.0], [1548.0, 1283.0], [1548.0, 1313.0], [885.0, 1313.0]]}, {"text": "proved 1.47%. The cosine learning rate is an effective strat-", "confidence": 0.9995152354240417, "text_region": [[885.0, 1313.0], [1548.0, 1313.0], [1548.0, 1343.0], [885.0, 1343.0]]}, {"text": "egy for text recognition. Next, when we increase the fea-", "confidence": 0.9977877140045166, "text_region": [[882.0, 1343.0], [1550.0, 1341.0], [1550.0, 1373.0], [882.0, 1375.0]]}, {"text": "ture map resolution and reduce the stride of the second down", "confidence": 0.9880514740943909, "text_region": [[885.0, 1373.0], [1552.0, 1373.0], [1552.0, 1402.0], [885.0, 1402.0]]}, {"text": "sampling feature map from (2,1) to (1,1), the accuracy will", "confidence": 0.9837576746940613, "text_region": [[887.0, 1405.0], [1552.0, 1405.0], [1552.0, 1435.0], [887.0, 1435.0]]}, {"text": "be improved 5.27%. Then, when we adjust the regulariza-", "confidence": 0.9892852306365967, "text_region": [[885.0, 1435.0], [1548.0, 1435.0], [1548.0, 1464.0], [885.0, 1464.0]]}, {"text": "tion parameters L2_decay from 0 to 1e - 5 further, the accu", "confidence": 0.9644016623497009, "text_region": [[885.0, 1467.0], [1545.0, 1467.0], [1545.0, 1496.0], [885.0, 1496.0]]}, {"text": "racy will be improved 3.4%. The feature map resolution and", "confidence": 0.9951817989349365, "text_region": [[887.0, 1496.0], [1552.0, 1496.0], [1552.0, 1526.0], [887.0, 1526.0]]}, {"text": "L2.decay have a great influence on the performance. Final.", "confidence": 0.97886061668396, "text_region": [[885.0, 1524.0], [1548.0, 1526.0], [1547.0, 1556.0], [885.0, 1554.0]]}, {"text": "using learning rate warm-up, the accuracy will be improved", "confidence": 0.993866503238678, "text_region": [[885.0, 1556.0], [1552.0, 1556.0], [1552.0, 1586.0], [885.0, 1586.0]]}, {"text": "0.62%. Using TIA data augmentation, the accuracy will be", "confidence": 0.9989514350891113, "text_region": [[887.0, 1588.0], [1552.0, 1588.0], [1552.0, 1618.0], [887.0, 1618.0]]}, {"text": "improved 0.91%. Learning rate warm-up and TIA also are", "confidence": 0.9949633479118347, "text_region": [[887.0, 1618.0], [1552.0, 1618.0], [1552.0, 1648.0], [887.0, 1648.0]]}, {"text": "effective strategies for text recognition.", "confidence": 0.9996153712272644, "text_region": [[883.0, 1645.0], [1326.0, 1650.0], [1326.0, 1680.0], [882.0, 1675.0]]}], "img_idx": 0, "score": 0.9888007640838623}
{"type": "text", "bbox": [887, 816, 1558, 1033], "res": [{"text": "Table [11compares the number of channel in the CRNN", "confidence": 0.9828254580497742, "text_region": [[912.0, 820.0], [1550.0, 820.0], [1550.0, 850.0], [912.0, 850.0]]}, {"text": "head for text recognition. Reduce the number of channe.", "confidence": 0.997264564037323, "text_region": [[887.0, 855.0], [1545.0, 855.0], [1545.0, 878.0], [887.0, 878.0]]}, {"text": "from 256 to 48, the model size is reduced from 23M to 4.6M", "confidence": 0.993796169757843, "text_region": [[887.0, 885.0], [1550.0, 885.0], [1550.0, 908.0], [887.0, 908.0]]}, {"text": "and the inference time has accelerated nearly 30%. However,", "confidence": 0.9987078309059143, "text_region": [[885.0, 912.0], [1550.0, 912.0], [1550.0, 942.0], [885.0, 942.0]]}, {"text": "the accuracy will not be affected. We can see the number of.", "confidence": 0.9804467558860779, "text_region": [[887.0, 946.0], [1550.0, 946.0], [1550.0, 969.0], [887.0, 969.0]]}, {"text": "channel in the head has a great influence on the model size", "confidence": 0.9857074022293091, "text_region": [[887.0, 974.0], [1552.0, 974.0], [1552.0, 1004.0], [887.0, 1004.0]]}, {"text": "of a lightweight text recognizer.", "confidence": 0.9983437061309814, "text_region": [[883.0, 1001.0], [1245.0, 1006.0], [1245.0, 1036.0], [882.0, 1031.0]]}], "img_idx": 0, "score": 0.9768811464309692}
{"type": "text", "bbox": [149, 1446, 819, 1723], "res": [{"text": "mentation) and RandAugment to train a direction classifier.", "confidence": 0.997182309627533, "text_region": [[146.0, 1419.0], [806.0, 1419.0], [806.0, 1448.0], [146.0, 1448.0]]}, {"text": "Table [8|shows the ablation study of input resolution and", "confidence": 0.9857969880104065, "text_region": [[171.0, 1446.0], [815.0, 1451.0], [815.0, 1483.0], [171.0, 1478.0]]}, {"text": "PACT quantization for direction classification. When the in-", "confidence": 0.9868943095207214, "text_region": [[148.0, 1480.0], [813.0, 1480.0], [813.0, 1510.0], [148.0, 1510.0]]}, {"text": "put resolution is adjusted from 3  32  100 to 3  48  192", "confidence": 0.9915993809700012, "text_region": [[148.0, 1510.0], [806.0, 1510.0], [806.0, 1540.0], [148.0, 1540.0]]}, {"text": "The classification accuracy has improved but the prediction", "confidence": 0.9944403767585754, "text_region": [[148.0, 1542.0], [813.0, 1542.0], [813.0, 1572.0], [148.0, 1572.0]]}, {"text": "speed is basically unchanged. Furthermore, we also verified", "confidence": 0.9804507493972778, "text_region": [[150.0, 1577.0], [813.0, 1577.0], [813.0, 1600.0], [150.0, 1600.0]]}, {"text": "quantization strategy is effective in accelerating the predic.", "confidence": 0.9936293959617615, "text_region": [[148.0, 1602.0], [806.0, 1602.0], [806.0, 1632.0], [148.0, 1632.0]]}, {"text": "tion speed of the text direction classifier. The model size", "confidence": 0.9955439567565918, "text_region": [[148.0, 1634.0], [813.0, 1634.0], [813.0, 1664.0], [148.0, 1664.0]]}, {"text": "is reduced 45.9% and the inference time has accelerated", "confidence": 0.9870105385780334, "text_region": [[146.0, 1664.0], [815.0, 1664.0], [815.0, 1694.0], [146.0, 1694.0]]}, {"text": "25.86%. Accuracy is slight promotion.", "confidence": 0.9923055768013, "text_region": [[143.0, 1691.0], [578.0, 1694.0], [577.0, 1726.0], [143.0, 1723.0]]}], "img_idx": 0, "score": 0.9766290783882141}
{"type": "text", "bbox": [888, 1676, 1557, 1923], "res": [{"text": "effective strategies for text recognition.", "confidence": 0.9996153712272644, "text_region": [[883.0, 1645.0], [1326.0, 1650.0], [1326.0, 1680.0], [882.0, 1675.0]]}, {"text": "Tabel13]shows the ablation study of PACT quantization", "confidence": 0.9874864816665649, "text_region": [[912.0, 1680.0], [1552.0, 1680.0], [1552.0, 1710.0], [912.0, 1710.0]]}, {"text": "for text recognition. When we use PACT quantization, the", "confidence": 0.9872678518295288, "text_region": [[885.0, 1712.0], [1552.0, 1712.0], [1552.0, 1742.0], [885.0, 1742.0]]}, {"text": "model size is reduced 67.39% and the inference time has ac-", "confidence": 0.9924684762954712, "text_region": [[885.0, 1742.0], [1545.0, 1742.0], [1545.0, 1771.0], [885.0, 1771.0]]}, {"text": "celerated 8.3%. Since there was no quantification on LSTM,", "confidence": 0.9958500862121582, "text_region": [[882.0, 1771.0], [1552.0, 1769.0], [1552.0, 1801.0], [882.0, 1804.0]]}, {"text": "The acceleration is not obvious. However, accuracy achieves", "confidence": 0.988231897354126, "text_region": [[887.0, 1804.0], [1552.0, 1804.0], [1552.0, 1833.0], [887.0, 1833.0]]}, {"text": "a significant improvement. Therefore, PACT quantization", "confidence": 0.9859297275543213, "text_region": [[887.0, 1833.0], [1552.0, 1833.0], [1552.0, 1863.0], [887.0, 1863.0]]}, {"text": "also is an effective strategy for reducing the model size of.", "confidence": 0.9886273741722107, "text_region": [[887.0, 1868.0], [1552.0, 1868.0], [1552.0, 1891.0], [887.0, 1891.0]]}, {"text": "a text recognizer.", "confidence": 0.9787870049476624, "text_region": [[887.0, 1900.0], [1076.0, 1900.0], [1076.0, 1923.0], [887.0, 1923.0]]}], "img_idx": 0, "score": 0.9739276766777039}
{"type": "text", "bbox": [888, 1033, 1557, 1158], "res": [{"text": "of a lightweight text recognizer.", "confidence": 0.9983437061309814, "text_region": [[883.0, 1001.0], [1245.0, 1006.0], [1245.0, 1036.0], [882.0, 1031.0]]}, {"text": "Tabel12 shows the ablation study of data augmentation,", "confidence": 0.9827017784118652, "text_region": [[912.0, 1036.0], [1552.0, 1036.0], [1552.0, 1066.0], [912.0, 1066.0]]}, {"text": "cosine learning rate decay, the stride of the second down", "confidence": 0.999481201171875, "text_region": [[885.0, 1066.0], [1552.0, 1066.0], [1552.0, 1095.0], [885.0, 1095.0]]}, {"text": "sampling feature map, regularization parameters L2_decay", "confidence": 0.9820562601089478, "text_region": [[885.0, 1098.0], [1550.0, 1098.0], [1550.0, 1128.0], [885.0, 1128.0]]}, {"text": "and learning rate warm-up for text recognition.", "confidence": 0.9942615032196045, "text_region": [[887.0, 1132.0], [1409.0, 1132.0], [1409.0, 1155.0], [887.0, 1155.0]]}, {"text": "To verify the advantages of each strategy, the setting of", "confidence": 0.996103048324585, "text_region": [[912.0, 1157.0], [1552.0, 1160.0], [1552.0, 1192.0], [912.0, 1189.0]]}], "img_idx": 0, "score": 0.9683802723884583}
{"type": "text", "bbox": [150, 1353, 818, 1449], "res": [{"text": "and RandAugment are useful for text direction classifica-", "confidence": 0.9966018199920654, "text_region": [[148.0, 1354.0], [808.0, 1354.0], [808.0, 1384.0], [148.0, 1384.0]]}, {"text": "tion. Therefore, in PP-OCR, we use BDA (base data aug-", "confidence": 0.9901356101036072, "text_region": [[143.0, 1384.0], [809.0, 1389.0], [808.0, 1421.0], [143.0, 1416.0]]}, {"text": "mentation) and RandAugment to train a direction classifier.", "confidence": 0.997182309627533, "text_region": [[146.0, 1419.0], [806.0, 1419.0], [806.0, 1448.0], [146.0, 1448.0]]}, {"text": "Table [8|shows the ablation study of input resolution and", "confidence": 0.9857969880104065, "text_region": [[171.0, 1446.0], [815.0, 1451.0], [815.0, 1483.0], [171.0, 1478.0]]}], "img_idx": 0, "score": 0.9569166302680969}
{"type": "text", "bbox": [150, 1802, 820, 1957], "res": [{"text": "Table [10] compares the performance of the different back.", "confidence": 0.9768855571746826, "text_region": [[148.0, 1801.0], [808.0, 1804.0], [808.0, 1836.0], [148.0, 1833.0]]}, {"text": "bones for text recognition. The accuracy, the model size", "confidence": 0.9934718012809753, "text_region": [[148.0, 1836.0], [811.0, 1836.0], [811.0, 1865.0], [148.0, 1865.0]]}, {"text": "and the inference time of the different scales of Mo-", "confidence": 0.9839152693748474, "text_region": [[150.0, 1870.0], [811.0, 1870.0], [811.0, 1893.0], [150.0, 1893.0]]}, {"text": "bileNetV3 change greatly. In PP-OCR, we choose Mo-", "confidence": 0.9914720058441162, "text_region": [[148.0, 1898.0], [813.0, 1898.0], [813.0, 1927.0], [148.0, 1927.0]]}, {"text": "bileNetV3_small_x0.5 to balance accuracy and efficiency.", "confidence": 0.9903360605239868, "text_region": [[143.0, 1925.0], [785.0, 1930.0], [785.0, 1959.0], [143.0, 1955.0]]}], "img_idx": 0, "score": 0.9565180540084839}
{"type": "text", "bbox": [151, 1197, 819, 1291], "res": [{"text": "Table 10: Compares the performance of the different back.", "confidence": 0.9954251050949097, "text_region": [[148.0, 1201.0], [808.0, 1201.0], [808.0, 1231.0], [148.0, 1231.0]]}, {"text": "bones for text recognition. The number of channel in the", "confidence": 0.9923624396324158, "text_region": [[148.0, 1231.0], [815.0, 1231.0], [815.0, 1263.0], [148.0, 1263.0]]}, {"text": "head is 256.", "confidence": 0.9690356254577637, "text_region": [[148.0, 1263.0], [282.0, 1263.0], [282.0, 1288.0], [148.0, 1288.0]]}], "img_idx": 0, "score": 0.9552088379859924}
{"type": "text", "bbox": [151, 779, 816, 841], "res": [{"text": "Table 9: Ablation study of data augmentation for direction", "confidence": 0.9983890056610107, "text_region": [[146.0, 777.0], [815.0, 779.0], [815.0, 811.0], [145.0, 809.0]]}, {"text": "classification.", "confidence": 0.999936044216156, "text_region": [[148.0, 814.0], [300.0, 814.0], [300.0, 839.0], [148.0, 839.0]]}], "img_idx": 0, "score": 0.950692892074585}
{"type": "text", "bbox": [888, 659, 1556, 752], "res": [{"text": "Table 11: Ablation study of the number of channel in the", "confidence": 0.9902981519699097, "text_region": [[882.0, 658.0], [1552.0, 662.0], [1552.0, 692.0], [882.0, 687.0]]}, {"text": "head for text recognition. The data augmentation is only", "confidence": 0.9955825805664062, "text_region": [[882.0, 694.0], [1550.0, 694.0], [1550.0, 724.0], [882.0, 724.0]]}, {"text": "used BDA.", "confidence": 0.999767541885376, "text_region": [[881.0, 717.0], [1014.0, 722.0], [1013.0, 754.0], [880.0, 749.0]]}], "img_idx": 0, "score": 0.9459794759750366}
{"type": "text", "bbox": [471, 312, 1094, 345], "res": [{"text": "Table 8: Ablation study of input resolution and PACT quantization for direction classification.", "confidence": 0.9932037591934204, "text_region": [[326.0, 312.0], [1370.0, 316.0], [1370.0, 346.0], [326.0, 341.0]]}], "img_idx": 0, "score": 0.5369571447372437}
{"type": "title", "bbox": [150, 1755, 439, 1790], "res": [{"text": "3.4Text Recognition", "confidence": 0.9998547434806824, "text_region": [[143.0, 1755.0], [439.0, 1758.0], [439.0, 1790.0], [143.0, 1787.0]]}], "img_idx": 0, "score": 0.8753474354743958}
{"type": "table", "bbox": [164, 879, 794, 1164], "res": {"cell_bbox": [[36.03806686401367, 79.92060089111328, 159.358154296875, 142.2290802001953], [221.31228637695312, 87.78782653808594, 329.6889343261719, 137.6400146484375], [356.91290283203125, 40.71321487426758, 462.67193603515625, 172.7137451171875], [494.1768798828125, 29.07155418395996, 604.0411987304688, 197.86009216308594], [14.711479187011719, 224.23629760742188, 183.71514892578125, 340.5734558105469], [226.79537963867188, 238.2158966064453, 313.8907470703125, 315.07562255859375], [389.6717529296875, 247.82846069335938, 424.4347229003906, 311.9017333984375], [529.2472534179688, 243.2971954345703, 569.0529174804688, 305.0859375], [23.09026336669922, 360.9586181640625, 189.74935913085938, 466.7745666503906], [230.02294921875, 381.897705078125, 313.767333984375, 449.16839599609375], [389.67779541015625, 377.8251037597656, 425.6455078125, 446.6029357910156], [517.102783203125, 381.8277893066406, 581.2734375, 445.3102722167969], [24.352264404296875, 506.2067565917969, 181.3551025390625, 602.0530395507812], [233.66046142578125, 518.2842407226562, 306.02392578125, 582.5367431640625], [393.59991455078125, 517.9619140625, 424.8064880371094, 582.0591430664062], [517.4559326171875, 517.1284790039062, 579.6820068359375, 581.2178344726562]], "html": "<html><body><table><thead><tr><td>Backbone MobileNetV3 small_x0.35 MobileNetV3_ small_x0.5</td><td>Accuracy 0.6288 0.6556</td><td>Model Size (M) 22 23</td><td>Inference Time (CPU, ms) 17 17.27</td></tr></thead><tbody><tr><td>MobileNetV3_ small_x1</td><td>0.6933</td><td>28</td><td>19.15</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table></body></html>"}, "img_idx": 0, "score": 0.9457328915596008}
{"type": "figure", "bbox": [926, 402, 1508, 622], "res": [{"text": "Inference", "confidence": 0.9530043005943298, "text_region": [[1375.0, 396.0], [1493.0, 402.0], [1491.0, 434.0], [1374.0, 428.0]]}, {"text": "the number", "confidence": 0.9999052286148071, "text_region": [[942.0, 419.0], [1067.0, 419.0], [1067.0, 445.0], [942.0, 445.0]]}, {"text": "Model", "confidence": 0.9996052980422974, "text_region": [[1252.0, 415.0], [1333.0, 415.0], [1333.0, 447.0], [1252.0, 447.0]]}, {"text": "Accuracy", "confidence": 0.9997386932373047, "text_region": [[1098.0, 428.0], [1213.0, 434.0], [1212.0, 466.0], [1097.0, 460.0]]}, {"text": "Time", "confidence": 0.9998369216918945, "text_region": [[1404.0, 433.0], [1464.0, 433.0], [1464.0, 461.0], [1404.0, 461.0]]}, {"text": "of channel", "confidence": 0.9994404911994934, "text_region": [[945.0, 449.0], [1065.0, 449.0], [1065.0, 474.0], [945.0, 474.0]]}, {"text": "Size (M)", "confidence": 0.9998364448547363, "text_region": [[1238.0, 447.0], [1344.0, 447.0], [1344.0, 479.0], [1238.0, 479.0]]}, {"text": "(CPU, ms)", "confidence": 0.967700719833374, "text_region": [[1371.0, 456.0], [1502.0, 461.0], [1500.0, 493.0], [1369.0, 488.0]]}, {"text": "256", "confidence": 0.9999046921730042, "text_region": [[982.0, 489.0], [1031.0, 496.0], [1027.0, 526.0], [978.0, 519.0]]}, {"text": "0.6556", "confidence": 0.9999749064445496, "text_region": [[1116.0, 497.0], [1196.0, 497.0], [1196.0, 522.0], [1116.0, 522.0]]}, {"text": "23", "confidence": 0.8449798822402954, "text_region": [[1275.0, 493.0], [1310.0, 493.0], [1310.0, 525.0], [1275.0, 525.0]]}, {"text": "17.27", "confidence": 0.9999386072158813, "text_region": [[1400.0, 493.0], [1469.0, 493.0], [1469.0, 525.0], [1400.0, 525.0]]}, {"text": "96", "confidence": 0.9994676113128662, "text_region": [[986.0, 525.0], [1026.0, 525.0], [1026.0, 555.0], [986.0, 555.0]]}, {"text": "0.6673", "confidence": 0.9999787211418152, "text_region": [[1116.0, 527.0], [1196.0, 527.0], [1196.0, 552.0], [1116.0, 552.0]]}, {"text": "8", "confidence": 0.9980601668357849, "text_region": [[1275.0, 525.0], [1305.0, 525.0], [1305.0, 555.0], [1275.0, 555.0]]}, {"text": "13.36", "confidence": 0.9999710321426392, "text_region": [[1400.0, 522.0], [1471.0, 522.0], [1471.0, 555.0], [1400.0, 555.0]]}, {"text": "64", "confidence": 0.9998799562454224, "text_region": [[986.0, 557.0], [1023.0, 557.0], [1023.0, 587.0], [986.0, 587.0]]}, {"text": "5.6", "confidence": 0.9999011158943176, "text_region": [[1270.0, 557.0], [1314.0, 557.0], [1314.0, 587.0], [1270.0, 587.0]]}, {"text": "12.64", "confidence": 0.9999421238899231, "text_region": [[1399.0, 549.0], [1472.0, 555.0], [1469.0, 590.0], [1396.0, 583.0]]}, {"text": "0.6642", "confidence": 0.9999821782112122, "text_region": [[1116.0, 559.0], [1196.0, 559.0], [1196.0, 584.0], [1116.0, 584.0]]}, {"text": "48", "confidence": 0.9998272657394409, "text_region": [[986.0, 589.0], [1026.0, 589.0], [1026.0, 619.0], [986.0, 619.0]]}, {"text": "0.6581", "confidence": 0.9999720454216003, "text_region": [[1113.0, 591.0], [1194.0, 591.0], [1194.0, 616.0], [1113.0, 616.0]]}, {"text": "4.6", "confidence": 0.9997310638427734, "text_region": [[1268.0, 589.0], [1312.0, 589.0], [1312.0, 619.0], [1268.0, 619.0]]}, {"text": "12.26", "confidence": 0.9999221563339233, "text_region": [[1402.0, 587.0], [1471.0, 587.0], [1471.0, 619.0], [1402.0, 619.0]]}], "img_idx": 0, "score": 0.8883227705955505}
{"type": "figure", "bbox": [262, 147, 1441, 278], "res": [{"text": "Input Resolution", "confidence": 0.9745538234710693, "text_region": [[263.0, 149.0], [485.0, 149.0], [485.0, 179.0], [263.0, 179.0]]}, {"text": "PACT Quantization", "confidence": 0.9995298981666565, "text_region": [[476.0, 146.0], [728.0, 151.0], [727.0, 181.0], [476.0, 176.0]]}, {"text": "Accuracy", "confidence": 0.999189019203186, "text_region": [[723.0, 154.0], [857.0, 154.0], [857.0, 176.0], [723.0, 176.0]]}, {"text": "Model Size (M)Inference Time (SD 855, ms)", "confidence": 0.9782727956771851, "text_region": [[873.0, 149.0], [1437.0, 149.0], [1437.0, 179.0], [873.0, 179.0]]}, {"text": "0.85", "confidence": 0.9998608231544495, "text_region": [[945.0, 173.0], [1006.0, 180.0], [1002.0, 214.0], [941.0, 207.0]]}, {"text": "3  32  100", "confidence": 0.9688680768013, "text_region": [[293.0, 183.0], [448.0, 183.0], [448.0, 209.0], [293.0, 209.0]]}, {"text": "0.9212", "confidence": 0.99997478723526, "text_region": [[758.0, 183.0], [843.0, 183.0], [843.0, 209.0], [758.0, 209.0]]}, {"text": "3.19", "confidence": 0.9999444484710693, "text_region": [[1233.0, 181.0], [1289.0, 181.0], [1289.0, 209.0], [1233.0, 209.0]]}, {"text": "3  48  192", "confidence": 0.9629901647567749, "text_region": [[293.0, 213.0], [446.0, 213.0], [446.0, 238.0], [293.0, 238.0]]}, {"text": "0.9403", "confidence": 0.9999425411224365, "text_region": [[758.0, 213.0], [841.0, 213.0], [841.0, 238.0], [758.0, 238.0]]}, {"text": "0.85", "confidence": 0.9999380111694336, "text_region": [[949.0, 213.0], [1002.0, 213.0], [1002.0, 241.0], [949.0, 241.0]]}, {"text": "3.21", "confidence": 0.9998845458030701, "text_region": [[1231.0, 209.0], [1289.0, 209.0], [1289.0, 243.0], [1231.0, 243.0]]}, {"text": "3  48  192", "confidence": 0.959341824054718, "text_region": [[293.0, 243.0], [448.0, 243.0], [448.0, 268.0], [293.0, 268.0]]}, {"text": "0.9456", "confidence": 0.9999387860298157, "text_region": [[760.0, 243.0], [843.0, 243.0], [843.0, 268.0], [760.0, 268.0]]}, {"text": "0.46", "confidence": 0.9999287724494934, "text_region": [[947.0, 243.0], [1005.0, 243.0], [1005.0, 270.0], [947.0, 270.0]]}, {"text": "2.38", "confidence": 0.9999513626098633, "text_region": [[1233.0, 241.0], [1289.0, 241.0], [1289.0, 268.0], [1233.0, 268.0]]}], "img_idx": 0, "score": 0.8878406286239624}
{"type": "figure", "bbox": [268, 401, 690, 741], "res": [{"text": "Data Augmentation", "confidence": 0.9999242424964905, "text_region": [[300.0, 406.0], [520.0, 406.0], [520.0, 429.0], [300.0, 429.0]]}, {"text": "Accuracy", "confidence": 0.9997943043708801, "text_region": [[571.0, 406.0], [677.0, 406.0], [677.0, 431.0], [571.0, 431.0]]}, {"text": "NO", "confidence": 0.9957268834114075, "text_region": [[387.0, 425.0], [440.0, 432.0], [436.0, 466.0], [382.0, 459.0]]}, {"text": "0.8879", "confidence": 0.9999710917472839, "text_region": [[582.0, 435.0], [665.0, 435.0], [665.0, 461.0], [582.0, 461.0]]}, {"text": "BDA", "confidence": 0.9995715618133545, "text_region": [[381.0, 465.0], [441.0, 465.0], [441.0, 493.0], [381.0, 493.0]]}, {"text": "0.9134", "confidence": 0.9999713897705078, "text_region": [[582.0, 465.0], [665.0, 465.0], [665.0, 490.0], [582.0, 490.0]]}, {"text": "BDA+CutMix", "confidence": 0.999859631061554, "text_region": [[330.0, 497.0], [487.0, 497.0], [487.0, 522.0], [330.0, 522.0]]}, {"text": "0.9083", "confidence": 0.9998461604118347, "text_region": [[582.0, 493.0], [668.0, 493.0], [668.0, 525.0], [582.0, 525.0]]}, {"text": "BDA+Mixup", "confidence": 0.9997966289520264, "text_region": [[333.0, 520.0], [488.0, 525.0], [487.0, 557.0], [332.0, 552.0]]}, {"text": "0.9104", "confidence": 0.9999316334724426, "text_region": [[582.0, 522.0], [668.0, 522.0], [668.0, 555.0], [582.0, 555.0]]}, {"text": "BDA+Cutout", "confidence": 0.9999038577079773, "text_region": [[335.0, 557.0], [487.0, 557.0], [487.0, 582.0], [335.0, 582.0]]}, {"text": "0.9081", "confidence": 0.9999151825904846, "text_region": [[580.0, 552.0], [665.0, 552.0], [665.0, 584.0], [580.0, 584.0]]}, {"text": "BDA+HideAndSeek", "confidence": 0.9997921586036682, "text_region": [[293.0, 584.0], [529.0, 584.0], [529.0, 614.0], [293.0, 614.0]]}, {"text": "0.8598", "confidence": 0.9999188780784607, "text_region": [[582.0, 584.0], [668.0, 584.0], [668.0, 616.0], [582.0, 616.0]]}, {"text": "BDA+GridMask", "confidence": 0.9999340176582336, "text_region": [[314.0, 614.0], [506.0, 614.0], [506.0, 644.0], [314.0, 644.0]]}, {"text": "0.9140", "confidence": 0.9999272227287292, "text_region": [[579.0, 609.0], [668.0, 615.0], [666.0, 647.0], [577.0, 641.0]]}, {"text": "BDA+RandomErasing", "confidence": 0.9999435544013977, "text_region": [[282.0, 644.0], [541.0, 646.0], [540.0, 678.0], [282.0, 676.0]]}, {"text": "0.9193", "confidence": 0.9999425411224365, "text_region": [[580.0, 644.0], [668.0, 644.0], [668.0, 676.0], [580.0, 676.0]]}, {"text": "BDA+AutoAugment", "confidence": 0.9999381303787231, "text_region": [[291.0, 674.0], [531.0, 676.0], [531.0, 708.0], [291.0, 706.0]]}, {"text": "0.9133", "confidence": 0.9999329447746277, "text_region": [[580.0, 674.0], [668.0, 674.0], [668.0, 706.0], [580.0, 706.0]]}, {"text": "BDA+RandAugment", "confidence": 0.9999617338180542, "text_region": [[291.0, 708.0], [534.0, 708.0], [534.0, 738.0], [291.0, 738.0]]}, {"text": "0.9212", "confidence": 0.9999551177024841, "text_region": [[580.0, 706.0], [668.0, 706.0], [668.0, 738.0], [580.0, 738.0]]}], "img_idx": 0, "score": 0.7849198579788208}
