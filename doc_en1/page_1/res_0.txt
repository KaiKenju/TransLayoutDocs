{"type": "text", "bbox": [176, 654, 791, 1267], "res": [{"text": "The Optical Character Recognition (OCR) systems have been", "confidence": 0.9995232820510864, "text_region": [[176.0, 655.0], [788.0, 655.0], [788.0, 685.0], [176.0, 685.0]]}, {"text": "widely used in various of application scenarios, such as of-", "confidence": 0.9926952719688416, "text_region": [[180.0, 688.0], [783.0, 688.0], [783.0, 710.0], [180.0, 710.0]]}, {"text": "fice automation (OA) systems, factory automations, online", "confidence": 0.9997072219848633, "text_region": [[178.0, 715.0], [785.0, 715.0], [785.0, 738.0], [178.0, 738.0]]}, {"text": "educations, map productions etc. However, OCR is still a", "confidence": 0.9843706488609314, "text_region": [[178.0, 742.0], [785.0, 742.0], [785.0, 765.0], [178.0, 765.0]]}, {"text": "challenging task due to the various of text appearances and", "confidence": 0.9828433394432068, "text_region": [[176.0, 768.0], [788.0, 768.0], [788.0, 798.0], [176.0, 798.0]]}, {"text": "the demand of computational efficiency. In this paper, we", "confidence": 0.9842426776885986, "text_region": [[176.0, 793.0], [788.0, 795.0], [788.0, 825.0], [175.0, 823.0]]}, {"text": "propose a practical ultra lightweight OCR system, i.e., PP-", "confidence": 0.9823050498962402, "text_region": [[176.0, 823.0], [785.0, 823.0], [785.0, 852.0], [176.0, 852.0]]}, {"text": "OCR. The overall model size of the PP-OCR is only 3.5M", "confidence": 0.9970899224281311, "text_region": [[178.0, 850.0], [783.0, 850.0], [783.0, 873.0], [178.0, 873.0]]}, {"text": "for recognizing 6622 Chinese characters and 2.8M for rec-", "confidence": 0.9911692142486572, "text_region": [[171.0, 875.0], [785.0, 878.0], [785.0, 908.0], [171.0, 905.0]]}, {"text": "ognizing 63 alphanumeric symbols, respectively. We intro", "confidence": 0.9922046661376953, "text_region": [[178.0, 910.0], [778.0, 910.0], [778.0, 933.0], [178.0, 933.0]]}, {"text": "duce a bag of strategies to either enhance the model ability", "confidence": 0.9895535111427307, "text_region": [[178.0, 937.0], [783.0, 937.0], [783.0, 960.0], [178.0, 960.0]]}, {"text": "or reduce the model size. The corresponding ablation exper", "confidence": 0.994051992893219, "text_region": [[176.0, 960.0], [778.0, 960.0], [778.0, 990.0], [176.0, 990.0]]}, {"text": "iments with the real data are also provided. Meanwhile, sev-", "confidence": 0.991470992565155, "text_region": [[176.0, 992.0], [783.0, 992.0], [783.0, 1015.0], [176.0, 1015.0]]}, {"text": "eral pre-trained models for the Chinese and English recog-", "confidence": 0.9891759157180786, "text_region": [[173.0, 1015.0], [785.0, 1018.0], [785.0, 1047.0], [173.0, 1045.0]]}, {"text": "nition are released, including a text detector (97K images", "confidence": 0.9998451471328735, "text_region": [[178.0, 1047.0], [783.0, 1047.0], [783.0, 1070.0], [178.0, 1070.0]]}, {"text": "are used), a direction classifier (600K images are used) as", "confidence": 0.9830369353294373, "text_region": [[178.0, 1075.0], [785.0, 1075.0], [785.0, 1098.0], [178.0, 1098.0]]}, {"text": "well as a text recognizer (17.9M images are used). Besides,", "confidence": 0.9977772235870361, "text_region": [[176.0, 1102.0], [785.0, 1102.0], [785.0, 1125.0], [176.0, 1125.0]]}, {"text": "the proposed PP-OCR are also verified in several other lan-", "confidence": 0.9947790503501892, "text_region": [[178.0, 1130.0], [783.0, 1130.0], [783.0, 1153.0], [178.0, 1153.0]]}, {"text": "guage recognition tasks, including French, Korean, Japanese", "confidence": 0.9765689373016357, "text_region": [[173.0, 1155.0], [785.0, 1153.0], [785.0, 1182.0], [173.0, 1185.0]]}, {"text": "and German. All of the above mentioned models are open-", "confidence": 0.9999128580093384, "text_region": [[176.0, 1182.0], [785.0, 1182.0], [785.0, 1212.0], [176.0, 1212.0]]}, {"text": "sourced and the codes are available in the GitHub repository,", "confidence": 0.9995242357254028, "text_region": [[173.0, 1208.0], [788.0, 1210.0], [788.0, 1240.0], [173.0, 1237.0]]}, {"text": "i.e., https://github.com/PaddlePaddle/PaddleOCR.", "confidence": 0.9857862591743469, "text_region": [[173.0, 1237.0], [674.0, 1237.0], [674.0, 1267.0], [173.0, 1267.0]]}], "img_idx": 0, "score": 0.9893036484718323}
{"type": "text", "bbox": [150, 1360, 817, 1817], "res": [{"text": "OCR (Optical Character Recognition), a technology which", "confidence": 0.9889971017837524, "text_region": [[148.0, 1361.0], [815.0, 1361.0], [815.0, 1391.0], [148.0, 1391.0]]}, {"text": "targets at recognizing text in images automatically as shown", "confidence": 0.991250216960907, "text_region": [[148.0, 1396.0], [813.0, 1396.0], [813.0, 1419.0], [148.0, 1419.0]]}, {"text": "in Figure1 has a long research history and a wide range", "confidence": 0.9936179518699646, "text_region": [[146.0, 1421.0], [811.0, 1421.0], [811.0, 1451.0], [146.0, 1451.0]]}, {"text": "of application scenarios, such as document electronization,", "confidence": 0.9987691044807434, "text_region": [[148.0, 1453.0], [813.0, 1453.0], [813.0, 1483.0], [148.0, 1483.0]]}, {"text": "identity authentication, digital financial system, and vehicle.", "confidence": 0.9954889416694641, "text_region": [[148.0, 1483.0], [815.0, 1483.0], [815.0, 1512.0], [148.0, 1512.0]]}, {"text": "license plate recognition. Moreover, in factory, products can", "confidence": 0.9951573014259338, "text_region": [[146.0, 1510.0], [815.0, 1513.0], [815.0, 1545.0], [145.0, 1542.0]]}, {"text": "be more conveniently managed by extracting the text infor-.", "confidence": 0.9809683561325073, "text_region": [[146.0, 1545.0], [811.0, 1545.0], [811.0, 1574.0], [146.0, 1574.0]]}, {"text": "mation of products automatically. Students' offline home-", "confidence": 0.9679707884788513, "text_region": [[148.0, 1574.0], [808.0, 1574.0], [808.0, 1604.0], [148.0, 1604.0]]}, {"text": "work or test paper can be electronized with an OCR system", "confidence": 0.9961814284324646, "text_region": [[148.0, 1606.0], [815.0, 1606.0], [815.0, 1636.0], [148.0, 1636.0]]}, {"text": "to make the communication between teachers and students", "confidence": 0.9982823729515076, "text_region": [[148.0, 1636.0], [813.0, 1636.0], [813.0, 1666.0], [148.0, 1666.0]]}, {"text": "more efficient. OCR can also be used for labeling the point", "confidence": 0.9970787167549133, "text_region": [[146.0, 1666.0], [815.0, 1666.0], [815.0, 1696.0], [146.0, 1696.0]]}, {"text": "of interests (POI) of a street view image, benefiting the", "confidence": 0.9679776430130005, "text_region": [[146.0, 1694.0], [815.0, 1696.0], [815.0, 1728.0], [145.0, 1726.0]]}, {"text": "map production efficiency. Rich application scenarios en-.", "confidence": 0.9858856797218323, "text_region": [[148.0, 1726.0], [813.0, 1726.0], [813.0, 1755.0], [148.0, 1755.0]]}, {"text": "dow OCR technology with great commercial value, mean-", "confidence": 0.993493378162384, "text_region": [[146.0, 1758.0], [808.0, 1758.0], [808.0, 1788.0], [146.0, 1788.0]]}, {"text": "while, a lot of challenges..", "confidence": 0.98707515001297, "text_region": [[148.0, 1788.0], [439.0, 1788.0], [439.0, 1817.0], [148.0, 1817.0]]}], "img_idx": 0, "score": 0.9881204962730408}
{"type": "text", "bbox": [887, 1588, 1554, 1833], "res": [{"text": "Figure[3] which usually changes dramatically for the factors", "confidence": 0.9961675405502319, "text_region": [[887.0, 1590.0], [1552.0, 1590.0], [1552.0, 1620.0], [887.0, 1620.0]]}, {"text": "such as perspective, scaling, bending, clutter, fonts, multi-", "confidence": 0.9892194867134094, "text_region": [[887.0, 1622.0], [1548.0, 1622.0], [1548.0, 1652.0], [887.0, 1652.0]]}, {"text": "lingual, blur, illumination, etc. Document text, as shown in", "confidence": 0.9817456603050232, "text_region": [[885.0, 1650.0], [1552.0, 1652.0], [1552.0, 1682.0], [885.0, 1680.0]]}, {"text": "Figure[4] is more often encountered in practical application.", "confidence": 0.9939147233963013, "text_region": [[887.0, 1682.0], [1548.0, 1682.0], [1548.0, 1712.0], [887.0, 1712.0]]}, {"text": "Different problems caused by the high density and long text", "confidence": 0.9984893202781677, "text_region": [[887.0, 1714.0], [1552.0, 1714.0], [1552.0, 1744.0], [887.0, 1744.0]]}, {"text": "need to be solved. Otherwise, document image text recogni-", "confidence": 0.9994781017303467, "text_region": [[882.0, 1742.0], [1548.0, 1744.0], [1547.0, 1774.0], [882.0, 1771.0]]}, {"text": "tion often comes with the need to structure the results, which", "confidence": 0.9860910177230835, "text_region": [[885.0, 1774.0], [1554.0, 1774.0], [1554.0, 1804.0], [885.0, 1804.0]]}, {"text": "introduced a new hard task.", "confidence": 0.9999474883079529, "text_region": [[887.0, 1808.0], [1194.0, 1808.0], [1194.0, 1831.0], [887.0, 1831.0]]}], "img_idx": 0, "score": 0.9724695682525635}
{"type": "text", "bbox": [888, 1833, 1553, 1957], "res": [{"text": "Computational Efficiency In practical, the images that", "confidence": 0.9948434233665466, "text_region": [[915.0, 1836.0], [1552.0, 1836.0], [1552.0, 1865.0], [915.0, 1865.0]]}, {"text": "need to be processed are usually massive, which makes high", "confidence": 0.9900276064872742, "text_region": [[887.0, 1870.0], [1550.0, 1870.0], [1550.0, 1893.0], [887.0, 1893.0]]}, {"text": "computational efficiency an important criterion for design-", "confidence": 0.9974124431610107, "text_region": [[887.0, 1898.0], [1548.0, 1898.0], [1548.0, 1927.0], [887.0, 1927.0]]}, {"text": "ing an OCR system. CPU is preferred to be used than GPU", "confidence": 0.9832814335823059, "text_region": [[882.0, 1927.0], [1552.0, 1925.0], [1552.0, 1955.0], [882.0, 1957.0]]}], "img_idx": 0, "score": 0.9567786455154419}
{"type": "text", "bbox": [886, 1465, 1555, 1529], "res": [{"text": "Figure 1: Some image results of the proposed PP-OCR sys-", "confidence": 0.9943974614143372, "text_region": [[885.0, 1467.0], [1550.0, 1467.0], [1550.0, 1496.0], [885.0, 1496.0]]}, {"text": "tem.", "confidence": 0.9983095526695251, "text_region": [[885.0, 1494.0], [937.0, 1502.0], [932.0, 1530.0], [881.0, 1521.0]]}], "img_idx": 0, "score": 0.9430939555168152}
{"type": "text", "bbox": [150, 1817, 818, 1910], "res": [{"text": "while, a lot of challenges..", "confidence": 0.98707515001297, "text_region": [[148.0, 1788.0], [439.0, 1788.0], [439.0, 1817.0], [148.0, 1817.0]]}, {"text": "Various of Text Appearances Text in image can be gen", "confidence": 0.9980134963989258, "text_region": [[176.0, 1820.0], [806.0, 1820.0], [806.0, 1849.0], [176.0, 1849.0]]}, {"text": "erally divided into two categories: scene text and document", "confidence": 0.9992828965187073, "text_region": [[148.0, 1849.0], [815.0, 1849.0], [815.0, 1879.0], [148.0, 1879.0]]}, {"text": "text. Scene text refers to the text in natural scene as shown in", "confidence": 0.9957298636436462, "text_region": [[148.0, 1881.0], [815.0, 1881.0], [815.0, 1911.0], [148.0, 1911.0]]}], "img_idx": 0, "score": 0.9392639994621277}
{"type": "text", "bbox": [656, 458, 1062, 492], "res": [{"text": "Baidu Inc.", "confidence": 0.9998655319213867, "text_region": [[799.0, 433.0], [915.0, 433.0], [915.0, 458.0], [799.0, 458.0]]}, {"text": "{duyuning, yangyehua} @baidu.com", "confidence": 0.99946129322052, "text_region": [[656.0, 461.0], [1065.0, 461.0], [1065.0, 493.0], [656.0, 493.0]]}], "img_idx": 0, "score": 0.7654149532318115}
{"type": "text", "bbox": [797, 426, 912, 460], "res": [{"text": "Baidu Inc.", "confidence": 0.9998655319213867, "text_region": [[799.0, 433.0], [915.0, 433.0], [915.0, 458.0], [799.0, 458.0]]}], "img_idx": 0, "score": 0.6577432155609131}
{"type": "text", "bbox": [213, 1928, 524, 1956], "res": [{"text": "Copyright O 2021, All rights reserved.", "confidence": 0.9821949005126953, "text_region": [[146.0, 1925.0], [536.0, 1927.0], [536.0, 1957.0], [145.0, 1955.0]]}], "img_idx": 0, "score": 0.5112174153327942}
{"type": "title", "bbox": [401, 265, 1314, 312], "res": [{"text": "PP-OCR: A Practical Ultra Lightweight OCR System", "confidence": 0.989284336566925, "text_region": [[400.0, 270.0], [1310.0, 273.0], [1310.0, 305.0], [400.0, 302.0]]}], "img_idx": 0, "score": 0.8909896016120911}
{"type": "title", "bbox": [364, 1312, 596, 1350], "res": [{"text": "1Introduction", "confidence": 0.9996004104614258, "text_region": [[363.0, 1318.0], [598.0, 1318.0], [598.0, 1347.0], [363.0, 1347.0]]}], "img_idx": 0, "score": 0.8615591526031494}
{"type": "title", "bbox": [315, 343, 1419, 424], "res": [{"text": "Yuning Du, Chenxia Li, Ruoyu Guo, Xiaoting Yin, Weiwei Liu,", "confidence": 0.994289219379425, "text_region": [[414.0, 348.0], [1305.0, 351.0], [1305.0, 383.0], [413.0, 380.0]]}, {"text": "Jun Zhou, Yifan Bai, Zilin Yu, Yehua Yang, Qingqing Dang, Haoshuang Wang", "confidence": 0.9968113303184509, "text_region": [[303.0, 390.0], [1411.0, 390.0], [1411.0, 422.0], [303.0, 422.0]]}], "img_idx": 0, "score": 0.8067152500152588}
{"type": "title", "bbox": [428, 602, 533, 634], "res": [{"text": "Abstract", "confidence": 0.9998567700386047, "text_region": [[425.0, 603.0], [538.0, 603.0], [538.0, 635.0], [425.0, 635.0]]}], "img_idx": 0, "score": 0.7740815877914429}
{"type": "figure", "bbox": [933, 598, 1497, 1429], "res": [{"text": "FP", "confidence": 0.5205105543136597, "text_region": [[1032.0, 626.0], [1120.0, 626.0], [1120.0, 642.0], [1032.0, 642.0]]}, {"text": "0.953", "confidence": 0.7592645287513733, "text_region": [[1381.0, 793.0], [1496.0, 788.0], [1497.0, 811.0], [1382.0, 816.0]]}, {"text": ": Mairie du I' 0.992.", "confidence": 0.9324293732643127, "text_region": [[1277.0, 951.0], [1427.0, 951.0], [1427.0, 976.0], [1277.0, 976.0]]}, {"text": "Palais du LOUVRE0.992", "confidence": 0.9925426244735718, "text_region": [[1282.0, 969.0], [1488.0, 969.0], [1488.0, 999.0], [1282.0, 999.0]]}, {"text": "3: les arts decoratifs0.983", "confidence": 0.9762017130851746, "text_region": [[1271.0, 990.0], [1478.0, 992.0], [1478.0, 1018.0], [1270.0, 1015.0]]}, {"text": "4: Musee du LOUVRE 0.990", "confidence": 0.9698408246040344, "text_region": [[1266.0, 1011.0], [1492.0, 1011.0], [1492.0, 1040.0], [1266.0, 1040.0]]}, {"text": "Mairie du \"", "confidence": 0.8793601393699646, "text_region": [[1032.0, 1037.0], [1144.0, 1028.0], [1146.0, 1060.0], [1034.0, 1069.0]]}, {"text": "Theatre.0.919", "confidence": 0.9912548661231995, "text_region": [[1280.0, 1038.0], [1407.0, 1038.0], [1407.0, 1054.0], [1280.0, 1054.0]]}, {"text": "du PALAIS- ROVAL 0.893", "confidence": 0.9720842838287354, "text_region": [[1284.0, 1054.0], [1490.0, 1054.0], [1490.0, 1077.0], [1284.0, 1077.0]]}, {"text": "Palais du LOUVRE", "confidence": 0.7373588681221008, "text_region": [[1034.0, 1079.0], [1204.0, 1094.0], [1201.0, 1126.0], [1031.0, 1111.0]]}, {"text": "ECORATIFS", "confidence": 0.972752571105957, "text_region": [[1113.0, 1134.0], [1215.0, 1134.0], [1215.0, 1157.0], [1113.0, 1157.0]]}, {"text": "LES ARTS D", "confidence": 0.8818801045417786, "text_region": [[1030.0, 1146.0], [1120.0, 1146.0], [1120.0, 1162.0], [1030.0, 1162.0]]}, {"text": "Mus6e du LOUVRE", "confidence": 0.8233094811439514, "text_region": [[1034.0, 1184.0], [1207.0, 1197.0], [1204.0, 1227.0], [1032.0, 1214.0]]}, {"text": "PALAIS-ROYAL", "confidence": 0.9040262699127197, "text_region": [[1035.0, 1251.0], [1132.0, 1251.0], [1132.0, 1276.0], [1035.0, 1276.0]]}], "img_idx": 0, "score": 0.9452057480812073}
